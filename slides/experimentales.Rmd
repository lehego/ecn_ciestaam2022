---
title: "Métodos experimentales"
author: "Irvin Rojas"
header-includes:
  - \usepackage{tikz}
  - \usetikzlibrary{shapes, shadows,arrows}
  - \usepackage{amsmath} 
  - \usepackage[utf8]{inputenc}
output:
  xaringan::moon_reader:
    css: [default, "libs/cide.css", metropolis-fonts, "https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap-grid.min.css", "https://use.fontawesome.com/releases/v5.7.2/css/all.css", "https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css"]
    seal: false
    chakra: "https://remarkjs.com/downloads/remark-latest.min.js"
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      titleSlideClass: ["middle", "center"]
      ratio: "16:9"
      beforeInit: ["https://platform.twitter.com/widgets.js", "libs/cols_macro.js"]
      navigation:
        scroll: false
---

class: title-slide

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      warning = F,
                      message = F, fig.path = "figures/")
library(tidyverse)
library(magick)
library(reticulate)
library(kableExtra)
library(xaringancolor)

xfun::pkg_load2(c('base64enc', 'htmltools', 'mime'))

knitr::opts_knit$set(root.dir = "C:/Users/rojas/Dropbox/presentations_sites/ecn_ciestaam2022")
```

.title[
# Métodos experimentales
]

.subtitle[
## Taller de Econometría CIESTAAM-UACh 2022
]

.author[
### Irvin Rojas <br> [rojasirvin.com](https://www.rojasirvin.com/) <br> [<i class="fab fa-github"></i>](https://github.com/rojasirvin) [<i class="fab fa-twitter"></i>](https://twitter.com/RojasIrvin) [<i class="ai ai-google-scholar"></i>](https://scholar.google.com/citations?user=FUwdSTMAAAAJ&hl=en)
]

---


---

class: inverse, middle, center

# La experimentación para resolver el problema del sesgo de selección

---
# Tratamiento aleatorio

Supongamos que tenemos la posibilidad de aleatorizar el tratamiento, es decir, hacer que $Y_i$ y $D_i$ sean independientes

En otras palabras, logramos que el valor esperado de la variable que nos interesa sea igual entre tratados y no tratados

Esto puede escribirse como $E(Y_{0i}|D_i=0)=E(Y_{0i}|D_i=1)$

De la definición de comparación observacional:

$$
\begin{aligned}
E(y_i|D_i=1)-E(y_i|D_i=0)=&E(y_{1i}|D_i=1)-E(y_{0i}|D_i=0)
\end{aligned}
$$

Sustituyendo el resultado de independencia:

$$
\begin{aligned}
E(y_i|D_i=1)-E(y_i|D_i=0)&=E(y_{1i}|D_i=1)-E(y_{0i}|D_i=1) \\
& =E(y_{1i}-y_{0i}|D_i=1) \\
& =\underbrace{E(y_{1i}-y_{0i})}_{\text{Efecto causal}}
\end{aligned}
$$

---

# No siempre es factible

La aleatorización resuelve muchas cosas, pero muchas veces no es factible

¿Qué tendríamos que hacer en el caso de estudio, "¿Los hospitales matan?"

Pensemos en un programa de empleo para ex convictos

Seguramente una comparación observacional indicaría que estos ganan menos que el resto de la población

Pero esto no significa que el programa cause un efecto negativo en el ingreso

Siempre tenemos que pensar en el contrafactual

---

# El experimento STAR

¿En qué consistió?

Dos tipos de tratamiento:

  - $T_1$: clase pequeña (13-17) con maestro de tiempo completo
  - $T_2$: tamaño normal pero con asistente para el maestro

Un grupo $C$ al que no se le hizo cambio alguno (22.4 alumnos en promedio)

¿Cuál es el efecto de tener clases más pequeñas?

¿Por qué esto sería relevante? ¿Qué implicaciones de política tendría?

---

# El balance

.pull-left[

El supuesto más importante en una evaluación experimental es que la única cosa que hace distintos a los grupos es recibir o no el tratamiento

En la práctica, recolectamos información de los grupos de tratamiento y control **antes** de llevar a cabo un programa

Esto es lo que se conoce como **línea base**

En estadística esto consiste en probar la hipótesis nula de que la media de las características que se observaron en la línea base son iguales antes del tratamiento
]

.pull-right[

```{r echo=FALSE, message=FALSE, warnings=FALSE, results='asis'}

variable <- c("Observables:", "Lunch gratis", "Blanco / asiático", "Edad (1985)", "", "Atrición", "Tamaño de clase","Calificación")
control <- c("",0.48,0.67,5.43,"",0.52,22.4,48.9)
t1 <- c("",0.47,0.68,5.44,"",0.49,15.1,54.7)
t2 <- c("",0.50,0.66,5.42,"",0.53,22.8,50.0)
pvalue <- c("",0.09,0.26,0.32,"",0.02,0.001,0.001)

table.balance <- data.frame(cbind(variable, control,t1,t2,pvalue))
colnames(table.balance) = c("Variable","`C`","`T_1`", "`T_2`", "`p`")

table.balance %>%
  kbl(align = "lcccc",
      escape = FALSE,
      full_width = FALSE) %>%
  kable_paper(c("hover", "condensed", "responsive")) %>% 
  add_header_above(c("Balance de observables" = 5 ),
                   bold = TRUE,
                   background = "white") %>% 
  footnote(general = "Tabla 2.2.1 de Angrist y Pischke (2009), Tabla 2.2.1.",
           general_title = "Nota:",
           footnote_as_chunk = T)

```
]

---

# El balance

.pull-left[
Las características observables son las filas

La *atrición* de un estudio es la cantidad de sujetos que dejan de participar

Las penúltima fila muestra que el tratamiento efectivamente modificó el tamaño promedio de los grupos

La última fila muestra las calificaciones promedio en un examen
]

.pull-right[

```{r echo=FALSE, message=FALSE, warnings=FALSE, results='asis'}
table.balance %>%
  kbl(align = "lcccc",
      escape = FALSE,
      full_width = FALSE) %>%
  kable_paper(c("hover", "condensed", "responsive")) %>% 
  add_header_above(c("Balance de observables" = 5 ),
                   bold = TRUE,
                   background = "white") %>% 
  footnote(general = "Tabla 2.2.1 de Angrist y Pischke (2009), Tabla 2.2.1.",
           general_title = "Nota:",
           footnote_as_chunk = T)

```
]


---

# Interpretación

La columna $p$ se interpreta como la *probabilidad de que la diferencia que encontramos se deba al error muestral*

En evaluación trabajamos con niveles de *tolerancia* sobre lo que podemos descubir solo por suerte

A esta tolerancia le llamamos *nivel de significancia* y la denotamos como $\alpha$

Por ejemplo, si $\alpha=0.05$, quiere decir que estamos dispuestos a vivir en una situación donde la tolerancia de encontrar una diferencia solo por azar es de 5%

Entonces, comparamos el valor $p$ estimado con $\alpha$

---

# El balance

.pull-left[
El porcentaje de niños que recibe lunch gratis es diferente entre grupos, pero la probabilidad de que estas diferencias sean cuestión de azar es de 9%

Cuando $p>\alpha$ decimos que la diferencia **no** es estadísticamente significativa

El tamaño promedio de los grupos es distinto entre los distintos grupos y dichas diferencias son estadísticamente significativas

]


.pull-right[

```{r echo=FALSE, message=FALSE, warnings=FALSE, results='asis'}
table.balance %>%
  kbl(align = "lcccc",
      escape = FALSE,
      full_width = FALSE) %>%
  kable_paper(c("hover", "condensed", "responsive")) %>% 
  add_header_above(c("Balance de observables" = 5 ),
                   bold = TRUE,
                   background = "white") %>% 
  footnote(general = "Tabla 2.2.1 de Angrist y Pischke (2009), Tabla 2.2.1.",
           general_title = "Nota:",
           footnote_as_chunk = T)

```
]


---

# Desventajas

Tiempo

Costo: 12 millones de USD del proyecto STAR

Preocupaciones legales y éticas

A veces es posible hacer experimentos, a veces es muy difícil y a veces es imposible

Usando métodos no experimentales, Angrist y Lavy (1999) encuentran resultados parecidos (pero con otros métodos)


---

# Resumen: prueba de hipótesis en evaluación

Un camino típico:

  - Formulamos una pregunta causal $D_i \to y_i$

  - Tengo razones para asumir que $D_i$ es independiente de $y_i$ (por ejemplo, hice un experimento)
  
  - Elijo un estadístico (como la media) y construyo $t$

  - El software me arroja $t(\hat{\beta})$ y $p$

  - Si $p>\alpha$, hay una probabilidad de observar $\hat{\beta}$ debido al error muestral mayor que $\alpha$
  
  - O, en términos de $t$, es altamente probable observar el estadístico bajo la $H_0$, por lo que no se rechaza la $H_0$
  
---

# Resumen: prueba de hipótesis en evaluación

Las hipótesis no son exclusivamente de efectos de tratamiento

Otras hipótesis
  - Las características observables están *balanceadas*
  - La atrición ocurrió al azar

---

class: inverse, middle, center

# Regresión para la idenfiticación de efectos causales

---

# Regresión para la idenfiticación de efectos causales

Con fines de simplificación, asumamos un efecto de tratamiento constante: $y_{1i}-y_{0i}=\rho$

Consideremos el valor observado para un individuo 
$$y_i=y_{0i}+(y_{1i}-y_{0i})D_i$$

Sumemos y restemos $E(y_{0i})$:

$$
\begin{aligned}
y_i&=E(y_{0i})+(y_{1i}-y_{0i})D_i+y_{0i}-E(y_{0i}) \\
&=\underbrace{\alpha}_{E(y_{0i})}+\underbrace{\rho}_{(y_{1i}-y_{0i})} D_i + \underbrace{\nu_i}_{y_{0i}-E(y_{0i})}
\end{aligned}
$$

Esta expresión nos indica que podemos evaluar el efecto del tratamiento con una regresión de $y$ en función del indicador de tratamiento $D$

El valor estimado de $\rho$ nos da el efecto del tratamiento

---

# Regresión para la idenfiticación de efectos causales

Ahora evaluemos la diferencia de valores esperados

$$
\begin{aligned}
&E(y|D_i=1)=\alpha+\rho+E(\nu_i|D_i=1) \\
&E(y|D_i=0)=\alpha+E(\nu_i|D_i=0)
\end{aligned}
$$


Restando

$$
\begin{aligned}
E(y|D_i=1)-E(y|D_i=0)&=\rho+\overbrace{E(\nu_i|D_i=1)-E(\nu_i|D_i=0)}^{\text{Sesgo de selección}}
\end{aligned}
$$

Es decir, el sesgo de selección es igual a la correlación entre el término de error de la regresión y $D_i$

Nuestro supuesto de independencia de la asignación del tratamiento implica entonces que el error de la regresión no está correlacionado con el tratamiento

---

# Diferencia de medias con regresión

$$
y_i=\alpha+\rho D_i + \nu_i
$$


Con una regresión, el coeficiente estimado sobre la constante $\hat{\alpha}$ se puede interpretar como la media del grupo de control

Y el coeficiente sobre la variable que indica si se recibió el tratamiento $\hat{\rho}$ indica las diferencias entre tratados y no tratados

Noten que los valores del estadístico $t$ y del valor $p$ en ambas pruebas son idénticos, por lo que las conclusiones son las mismas

---

# Regresión corta y larga

Con un tratamiento binario y asignado aleatoriamente, podemos estimar el efecto usando una regresión:

$$y_i=\alpha+\beta D_i + u_i$$

Es muy común, sin embargo, usar **controles**

Si una serie de características $X$ no está correlacionada con $D_i$, se puede incluir en una versión larga de la regresión antes descrita

$$y_i=\alpha+\beta D_i + X_i'\gamma + u_i$$

El valor numérico de $\hat{\beta}$ en la regresión larga será muy cercano al obtenido con la regresión corta, pero se incrementa la precisión de los parámetros estimados

En R, haríamos algo así

```{r, echo=T, eval=F, results=F}
lm(y ~ T + x1 + x2 + x3,
   data = datos)
```

---

# El impacto de STAR con regresión

La Tabla 2.2.2 en MHE muestra los efectos de tratamiento estimados con regresión: 

$$calificacion_i=\alpha+\beta_1 T_{1i} + \beta_2 T_{2i} + B'X_i + u_i$$

```{r table.star, echo=FALSE, message=FALSE, warnings=FALSE, results='asis'}

variable <- c("`T_1`: Clase pequeña", " ", "`T_2`: Clase pequeña y asistente", " ", "Efectos fijos de escuela", "Controles")
r1 <- c("4.82", "(2.19)", "0.12", "(2.23)","No","No")
r2 <- c("5.37","(1.26)","0.29","(1.13)","Sí","No")
r3 <- c("5.36","(1.21)","0.53","(1.09)","Sí","`X_1`")
r4 <- c("5.37","(1.19)","0.31","(1.07)","Sí","`X_1+X_2`")

table.star <- data.frame(cbind(variable, r1, r2, r3, r4))

colnames(table.star) = c("Variable explicativa","(1)","(2)","(3)","(4)")

table.star %>%
  kbl(align = "lcccc",
      escape = FALSE,
      full_width = FALSE) %>%  kable_paper(c("hover", "condensed", "responsive")) %>%
  add_header_above(c("Efectos experimentales del tamaño del grupo en las calificaciones" = 5 ),
                   bold = TRUE,
                   background = "white") %>% 
  footnote(general = "Tabla 2.2.2 en Angrist y Pischke (2009)",
           general_title = "Nota:",
           footnote_as_chunk = T)
```


---

# Ejemplo

---

class: center, middle
Presentación creada usando el paquete [**xaringan**](https://github.com/yihui/xaringan) en R.

El *chakra* viene de [remark.js](https://remarkjs.com), [**knitr**](http://yihui.org/knitr), y [R Markdown](https://rmarkdown.rstudio.com).

Material de clase en versión preliminar.

**No reproducir, no distribuir, no citar.**